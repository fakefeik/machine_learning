{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import Imputer, OneHotEncoder, LabelEncoder\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, StratifiedKFold\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.concat([pd.read_csv('X.train.csv'), pd.read_csv('y.train.csv')], axis=1)\n",
    "test = pd.read_csv('X.test.csv')\n",
    "meta = pd.read_csv('MetaData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>...</th>\n",
       "      <th>V1323</th>\n",
       "      <th>V1324</th>\n",
       "      <th>V1325</th>\n",
       "      <th>V1326</th>\n",
       "      <th>V1327</th>\n",
       "      <th>V1328</th>\n",
       "      <th>V1329</th>\n",
       "      <th>V1330</th>\n",
       "      <th>V1331</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>826.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>242.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1038.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>971.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1331 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       V2   V3  V4   V5   V6   V7   V8        V9       V10  V11  ...    V1323  \\\n",
       "0   826.0  0.0   0  0.0  0.0  0.0  0.0       NaN       NaN  0.0  ...      0.0   \n",
       "1    15.0  0.0   0  0.0  0.0  0.0  0.0  0.030303  0.083333  0.0  ...      0.0   \n",
       "2   242.0  0.0   0  0.0  0.0  0.0  0.0       NaN       NaN  0.0  ...      1.0   \n",
       "3  1038.0  0.0   0  0.0  0.0  0.0  0.0       NaN       NaN  0.0  ...      0.5   \n",
       "4   971.0  0.0   0  0.0  0.0  0.0  0.0       NaN       NaN  0.0  ...      0.0   \n",
       "\n",
       "   V1324  V1325  V1326  V1327  V1328  V1329  V1330  V1331  label  \n",
       "0    0.0    0.0    1.0    1.0    0.0    NaN    0.0    0.5      0  \n",
       "1    1.0    0.0    0.0    0.0    0.5    0.0    0.5    0.0      0  \n",
       "2    0.0    0.5    0.0    0.0    1.0    0.0    0.0    0.5      0  \n",
       "3    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.5      0  \n",
       "4    1.0    0.0    0.5    0.0    0.0    0.0    0.0    0.0      0  \n",
       "\n",
       "[5 rows x 1331 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>...</th>\n",
       "      <th>V1322</th>\n",
       "      <th>V1323</th>\n",
       "      <th>V1324</th>\n",
       "      <th>V1325</th>\n",
       "      <th>V1326</th>\n",
       "      <th>V1327</th>\n",
       "      <th>V1328</th>\n",
       "      <th>V1329</th>\n",
       "      <th>V1330</th>\n",
       "      <th>V1331</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>685.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>0.097222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>91.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>0.097222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>332.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>714.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1330 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       V2   V3  V4   V5   V6   V7   V8        V9       V10  V11  ...    V1322  \\\n",
       "0   685.0  0.0   0  0.0  0.0  0.0  0.0  0.010101  0.097222  0.0  ...      0.5   \n",
       "1  1150.0  0.0   0  0.0  0.0  0.0  0.0  0.010101  0.083333  0.0  ...      0.5   \n",
       "2    91.0  0.0   1  0.0  0.0  0.0  1.0  0.010101  0.097222  0.0  ...      0.0   \n",
       "3   332.0  0.0   1  0.0  0.0  0.0  1.0       NaN       NaN  0.0  ...      0.5   \n",
       "4   714.0  0.0   1  0.0  0.0  1.0  1.0       NaN       NaN  NaN  ...      0.5   \n",
       "\n",
       "   V1323  V1324  V1325  V1326  V1327  V1328  V1329  V1330  V1331  \n",
       "0    0.5    0.5    0.0    0.5    0.5    0.5    0.0    0.0    0.0  \n",
       "1    0.5    0.5    0.0    0.5    0.0    0.0    0.0    0.0    0.5  \n",
       "2    0.5    0.5    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "3    0.5    0.5    0.0    0.5    0.0    0.0    NaN    0.0    0.0  \n",
       "4    1.0    0.0    0.0    0.0    0.0    0.0    NaN    0.0    0.0  \n",
       "\n",
       "[5 rows x 1330 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>varnum</th>\n",
       "      <th>type</th>\n",
       "      <th>Column Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>V2</td>\n",
       "      <td>char</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>V3</td>\n",
       "      <td>num</td>\n",
       "      <td>Category</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>V4</td>\n",
       "      <td>num</td>\n",
       "      <td>Category</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>V5</td>\n",
       "      <td>num</td>\n",
       "      <td>Category</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>V6</td>\n",
       "      <td>num</td>\n",
       "      <td>Category</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  varnum  type Column Type\n",
       "0     V2  char     Numeric\n",
       "1     V3   num    Category\n",
       "2     V4   num    Category\n",
       "3     V5   num    Category\n",
       "4     V6   num    Category"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = meta[meta['Column Type'] == 'Numeric']['varnum'].tolist()\n",
    "cat = meta[meta['Column Type'] == 'Category']['varnum'].tolist()\n",
    "cats = []\n",
    "for c in cat:\n",
    "    v = test[c].value_counts().index.tolist()\n",
    "    if len(v) == 2 and 0 in v and 1 in v:\n",
    "        cats.append(c)\n",
    "\n",
    "def leave_num(data):\n",
    "    return data[num]\n",
    "\n",
    "def leave_bool(data):  \n",
    "    return data[num + cats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def onehot_encode(train, test):\n",
    "    first_n = train.shape[0]\n",
    "    onehot = pd.get_dummies(pd.concat([train, test]), columns=cat)\n",
    "    return onehot[:first_n], onehot[first_n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save(clf, X_train, X_test):\n",
    "    clf.fit(X_train, train.label)\n",
    "\n",
    "    Y_test = pd.DataFrame()\n",
    "    Y_test['Id'] = np.arange(X_test.shape[0])\n",
    "    Y_test['Prediction'] = clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    Y_test.to_csv('res.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_imp, X_test_imp = train.drop('label', axis=1).fillna(-1), test.fillna(-1)\n",
    "X_train_num, X_test_num = leave_num(X_train_imp), leave_num(X_test_imp)\n",
    "X_train_bool, X_test_bool = leave_bool(X_train_imp), leave_bool(X_test_imp)\n",
    "X_train_onehot, X_test_onehot = onehot_encode(X_train_imp, X_test_imp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сначала была предпринята попытка улучшить baseline решение - подбор параметров `min_samples_leaf` и `max_features`, а также выставление какого-то большого числа `n_estimators` для случайного леса. В результате запуска `GridSearchCV` были подобраны `min_samples_leaf=11, max_features=200`, количество деревьев было выставлено в `n_estimators=20000`. Были испробованы разные методы заполнения пропусков - `most_frequent, fillna(0), fillna(-1)`, в результате последний показал наилучшее качество. Кажется, это произошло из-за того, что часто в данных образуются пропуски из-за каких-то специфических причин и лучше это явно обозначать (в данном случае поставив в значение признака `-1`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12],\n",
    "    'max_features': [50, 100, 200, 'sqrt', 'log2']\n",
    "}\n",
    "clf = RandomForestClassifier(n_estimators=200, n_jobs=-1, random_state=42, criterion='entropy')\n",
    "optimizer = GridSearchCV(clf, param_grid, scoring='neg_log_loss', cv=5)\n",
    "optimizer.fit(X_train_imp, train.label)\n",
    "optimizer.best_estimator_, optimizer.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=20000, n_jobs=-1, random_state=42,\n",
    "                             min_samples_leaf=11, max_features=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21952912240018216"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-np.mean(cross_val_score(clf, X_train_imp, train.label, scoring='neg_log_loss', cv=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save(clf, X_train_imp, X_test_imp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее был произведен еще один подбор параметров (в `max_features` добавлены бОльшие значения, а также попробован энтропийный критерий вместо критерия джини). В результате были подобраны параметры `min_samples_leaf=7, max_features=400`. Ошибка оказалась меньше, чем в предыдущей попытке, поэтому в дальнейшем использовался `criterion='entropy'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "             max_depth=None, max_features=400, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=7, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=-1,\n",
       "             oob_score=False, random_state=42, verbose=0, warm_start=False),\n",
       " -0.21660566063133974)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'min_samples_leaf': [2, 3, 5, 7, 9, 11, 12],\n",
    "    'max_features': [200, 300, 400, 'sqrt', 'log2']\n",
    "}\n",
    "clf = RandomForestClassifier(n_estimators=200, n_jobs=-1, random_state=42, criterion='entropy')\n",
    "optimizer = GridSearchCV(clf, param_grid, scoring='neg_log_loss', cv=5)\n",
    "optimizer.fit(X_train_imp, train.label)\n",
    "optimizer.best_estimator_, optimizer.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=20000, n_jobs=-1, random_state=42,\n",
    "                             min_samples_leaf=7, max_features=400, criterion='entropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21714792455484938"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-np.mean(cross_val_score(clf, X_train_imp, train.label, scoring='neg_log_loss', cv=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save(clf, X_train_imp, X_test_imp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее был произведен One-hot encoding, после чего была попытка обучить на этих данных логистическую регрессию, а также случайный лес и сравнить с предыдущими результатами. Видно, что результат получился хуже как для логистической регрессии, так и для случайного леса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(LogisticRegression(C=0.13, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "           penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
       "           verbose=0, warm_start=False), -0.2271032613027047)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'C': [0.01, 0.13, 0.14, 0.15,0.16, 0.5]}\n",
    "clf = LogisticRegression(penalty='l1', random_state=42)\n",
    "optimizer = GridSearchCV(clf, param_grid, scoring='neg_log_loss', cv=5, n_jobs=-1)\n",
    "optimizer.fit(X_train_onehot, train.label)\n",
    "optimizer.best_estimator_, optimizer.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "             max_depth=None, max_features=100, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=7, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, n_estimators=500, n_jobs=-1,\n",
       "             oob_score=False, random_state=42, verbose=0, warm_start=False),\n",
       " -0.22095191148333732)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "    'max_features': [50, 100, 'sqrt', 'log2']\n",
    "}\n",
    "clf = RandomForestClassifier(n_estimators=500, n_jobs=-1, random_state=42)\n",
    "optimizer = GridSearchCV(clf, param_grid, scoring='neg_log_loss', cv=5)\n",
    "optimizer.fit(X_train_onehot, train.label)\n",
    "optimizer.best_estimator_, optimizer.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=500, max_features=100, random_state=42,\n",
    "                             min_samples_leaf=10, n_jobs=-1)\n",
    "save(clf, X_train_onehot, X_test_onehot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее для логистической регрессии произведена попытка обучиться только на числовых данных и на категориальных данных, у которых только 2 категории (0 и 1) [назовем их булевыми]. Видно, что ошибка при обучении только на числовых данных больше, чем при обучении на числовых и булевых, поэтому в дальнейшем использовалась логистическая регрессия на числовых и булевых признаках."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(LogisticRegression(C=0.43, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "           penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
       "           verbose=0, warm_start=False), -0.22472507144967466)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'C': [0.43, 0.45, 0.47, 0.5, 0.55]}\n",
    "clf = LogisticRegression(penalty='l1', random_state=42)\n",
    "optimizer = GridSearchCV(clf, param_grid, scoring='neg_log_loss', cv=5, n_jobs=-1)\n",
    "optimizer.fit(X_train_num, train.label)\n",
    "optimizer.best_estimator_, optimizer.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(LogisticRegression(C=0.197, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "           penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
       "           verbose=0, warm_start=False), -0.2226198537009394)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'C': [0.196, 0.197, 0.199, 0.22]}\n",
    "clf = LogisticRegression(penalty='l1', random_state=42)\n",
    "optimizer = GridSearchCV(clf, param_grid, scoring='neg_log_loss', cv=5, n_jobs=-1)\n",
    "optimizer.fit(X_train_bool, train.label)\n",
    "optimizer.best_estimator_, optimizer.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(penalty='l1', random_state=42, C=0.199)\n",
    "save(clf, X_train_bool, X_test_bool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также было проверено предположение, что ошибка может уменьшиться при балансировке данных (не уменьшилась)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(LogisticRegression(C=0.27, class_weight='balanced', dual=False,\n",
       "           fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "           multi_class='ovr', n_jobs=1, penalty='l1', random_state=42,\n",
       "           solver='liblinear', tol=0.0001, verbose=0, warm_start=False),\n",
       " -0.46652655986918351)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'C': [0.196, 0.197, 0.199, 0.27, 0.3, 0.33, 0.5, 1]}\n",
    "clf = LogisticRegression(penalty='l1', random_state=42, class_weight='balanced')\n",
    "optimizer = GridSearchCV(clf, param_grid, scoring='neg_log_loss', cv=5, n_jobs=-1)\n",
    "optimizer.fit(X_train_bool, train.label)\n",
    "optimizer.best_estimator_, optimizer.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Далее из лабы был позаимствован `BlendingClassifier` с небольшими изменениями: так как ранее мы показали, что LogisticRegression и RandomForest показывают наилучшие результаты на разных данных, в конструктор были добавлены параметры `clf1_preprocess`, `clf2_preprocess` - функции, которые преобразуют исходные фичи в фичи, нужные конкретному классификатору. По умолчанию, если ничего не передать, эти функции ничего не делают с `X`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BlendingClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, clf1, clf2, clf1_preprocess=lambda x: x, clf2_preprocess=lambda x: x, alpha=0.5):\n",
    "        self.clf1 = clf1\n",
    "        self.clf2 = clf2\n",
    "        self.clf1_preprocess = clf1_preprocess\n",
    "        self.clf2_preprocess = clf2_preprocess\n",
    "        self.alpha = alpha\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.clf1.fit(self.clf1_preprocess(X), y)\n",
    "        self.clf2.fit(self.clf2_preprocess(X), y)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        clf1_pred = self.clf1.predict(self.clf1_preprocess(X))\n",
    "        clf2_pred = self.clf2.predict(self.clf2_preprocess(X))\n",
    "        return clf1_pred*self.alpha + clf2_pred*(1 - self.alpha)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        clf1_pred_proba = self.clf1.predict_proba(self.clf1_preprocess(X))\n",
    "        clf2_pred_proba = self.clf2.predict_proba(self.clf2_preprocess(X))\n",
    "        return clf1_pred_proba*self.alpha + clf2_pred_proba*(1 - self.alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_params_score(alphas, scores):\n",
    "    means = np.zeros(len(scores))\n",
    "    stds = np.zeros(len(scores))\n",
    "    for i, score in enumerate(scores):\n",
    "        means[i] = np.mean(score)\n",
    "        stds[i] = np.std(score)\n",
    "\n",
    "    plt.errorbar(range(len(scores)), means, xerr=0.5, yerr=2*stds, linestyle='', fmt='o')\n",
    "    plt.xticks(range(len(scores)), alphas, rotation='vertical')\n",
    "    plt.xlabel('alpha')\n",
    "    plt.ylabel('score')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'C': [0.196, 0.197, 0.199, 0.27, 0.3, 0.33, 0.5, 1]}\n",
    "clf = LogisticRegression(penalty='l1', random_state=42)\n",
    "optimizer = GridSearchCV(clf, param_grid, scoring='neg_log_loss', cv=5, n_jobs=-1)\n",
    "optimizer.fit(X_train_bool, train.label)\n",
    "optimizer.best_estimator_, optimizer.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha: 0.1, score: -0.22089369758867633\n",
      "alpha: 0.2, score: -0.21947181709087077\n",
      "alpha: 0.30000000000000004, score: -0.21833591945853176\n",
      "alpha: 0.4, score: -0.21745182582475814\n",
      "alpha: 0.5, score: -0.21679951089684288\n",
      "alpha: 0.6000000000000001, score: -0.2163684807066911\n",
      "alpha: 0.7000000000000001, score: -0.21615612269957074\n",
      "alpha: 0.8, score: -0.21616799515539106\n",
      "alpha: 0.9, score: -0.21642051523865763\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZQAAAF0CAYAAAAEgc8iAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x174284fda20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clf1 = RandomForestClassifier(n_estimators=1000, min_samples_leaf=2, max_features=200,\n",
    "                              criterion='entropy', random_state=42, n_jobs=-1)\n",
    "clf2 = LogisticRegression(penalty='l1', random_state=42, C=0.2)\n",
    "alphas = list(map(lambda i: i*0.1, range(1, 10)))\n",
    "scores = [0]*len(alphas)\n",
    "for i, alpha in enumerate(alphas):\n",
    "    blending = BlendingClassifier(clf1, clf2, clf2_preprocess=leave_bool, alpha=alpha)\n",
    "    scores[i] = cross_val_score(blending, X_train_imp, train.label, cv=5, scoring='neg_log_loss')\n",
    "    print(f'alpha: {alpha}, score: {scores[i].mean()}')\n",
    "plot_params_score(alphas, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = RandomForestClassifier(n_estimators=10000, min_samples_leaf=2, max_features=200,\n",
    "                              criterion='entropy', random_state=42, n_jobs=-1)\n",
    "clf2 = LogisticRegression(penalty='l1', random_state=42, C=0.2)\n",
    "clf = BlendingClassifier(clf1, clf2, clf2_preprocess=leave_bool, alpha=0.8)\n",
    "save(clf, X_train_imp, X_test_imp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В итоге с помощью такого блендинга с `alpha=0.8` удалось добиться\n",
    "\n",
    "`Public Score: 0.23006`,\n",
    "\n",
    "`Private Score: 0.21227`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После пары про PCA был испробован этот метод - теперь логистическая регрессия на числовых и булевых признаках в блендинге заменена на логрег на n признаках после PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pca_0</th>\n",
       "      <th>pca_1</th>\n",
       "      <th>pca_2</th>\n",
       "      <th>pca_3</th>\n",
       "      <th>pca_4</th>\n",
       "      <th>pca_5</th>\n",
       "      <th>pca_6</th>\n",
       "      <th>pca_7</th>\n",
       "      <th>pca_8</th>\n",
       "      <th>pca_9</th>\n",
       "      <th>...</th>\n",
       "      <th>pca_20</th>\n",
       "      <th>pca_21</th>\n",
       "      <th>pca_22</th>\n",
       "      <th>pca_23</th>\n",
       "      <th>pca_24</th>\n",
       "      <th>pca_25</th>\n",
       "      <th>pca_26</th>\n",
       "      <th>pca_27</th>\n",
       "      <th>pca_28</th>\n",
       "      <th>pca_29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>397.223524</td>\n",
       "      <td>9.202526</td>\n",
       "      <td>-2.189962</td>\n",
       "      <td>4.549270</td>\n",
       "      <td>-2.860389</td>\n",
       "      <td>-0.661128</td>\n",
       "      <td>-1.127714</td>\n",
       "      <td>-1.576609</td>\n",
       "      <td>2.435424</td>\n",
       "      <td>-0.214111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.725411</td>\n",
       "      <td>-1.880986</td>\n",
       "      <td>-1.253019</td>\n",
       "      <td>2.886256</td>\n",
       "      <td>-0.980574</td>\n",
       "      <td>2.297412</td>\n",
       "      <td>1.228414</td>\n",
       "      <td>-0.378631</td>\n",
       "      <td>-0.605802</td>\n",
       "      <td>0.823404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-413.796002</td>\n",
       "      <td>-2.642708</td>\n",
       "      <td>-1.816578</td>\n",
       "      <td>3.667889</td>\n",
       "      <td>-3.706980</td>\n",
       "      <td>-2.615337</td>\n",
       "      <td>2.154200</td>\n",
       "      <td>0.870472</td>\n",
       "      <td>-1.079709</td>\n",
       "      <td>-1.906726</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.719804</td>\n",
       "      <td>1.113808</td>\n",
       "      <td>-1.419744</td>\n",
       "      <td>0.418493</td>\n",
       "      <td>0.472745</td>\n",
       "      <td>-1.704450</td>\n",
       "      <td>1.735314</td>\n",
       "      <td>0.174928</td>\n",
       "      <td>-0.530689</td>\n",
       "      <td>0.675752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-186.792513</td>\n",
       "      <td>-4.251938</td>\n",
       "      <td>-4.995192</td>\n",
       "      <td>4.231895</td>\n",
       "      <td>2.960767</td>\n",
       "      <td>1.232992</td>\n",
       "      <td>-1.997857</td>\n",
       "      <td>-2.006408</td>\n",
       "      <td>-1.497303</td>\n",
       "      <td>1.266953</td>\n",
       "      <td>...</td>\n",
       "      <td>1.144931</td>\n",
       "      <td>0.094340</td>\n",
       "      <td>-0.533998</td>\n",
       "      <td>-0.873726</td>\n",
       "      <td>-1.637557</td>\n",
       "      <td>0.221892</td>\n",
       "      <td>-0.282241</td>\n",
       "      <td>0.688962</td>\n",
       "      <td>1.135661</td>\n",
       "      <td>1.948798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>609.182722</td>\n",
       "      <td>-3.988165</td>\n",
       "      <td>0.875283</td>\n",
       "      <td>-6.216485</td>\n",
       "      <td>2.647138</td>\n",
       "      <td>-0.395348</td>\n",
       "      <td>2.577097</td>\n",
       "      <td>-1.594666</td>\n",
       "      <td>1.456206</td>\n",
       "      <td>-1.572396</td>\n",
       "      <td>...</td>\n",
       "      <td>2.252659</td>\n",
       "      <td>-1.107131</td>\n",
       "      <td>-1.518347</td>\n",
       "      <td>-1.274131</td>\n",
       "      <td>0.044414</td>\n",
       "      <td>0.670109</td>\n",
       "      <td>0.130090</td>\n",
       "      <td>2.876533</td>\n",
       "      <td>-0.455379</td>\n",
       "      <td>-1.370996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>542.184498</td>\n",
       "      <td>-3.108270</td>\n",
       "      <td>1.562811</td>\n",
       "      <td>-5.742595</td>\n",
       "      <td>-0.700203</td>\n",
       "      <td>-0.212724</td>\n",
       "      <td>2.938653</td>\n",
       "      <td>2.474078</td>\n",
       "      <td>4.090147</td>\n",
       "      <td>-0.824463</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.404799</td>\n",
       "      <td>1.965380</td>\n",
       "      <td>-1.486253</td>\n",
       "      <td>-1.266973</td>\n",
       "      <td>-2.139169</td>\n",
       "      <td>-0.847958</td>\n",
       "      <td>-0.288191</td>\n",
       "      <td>1.387620</td>\n",
       "      <td>-0.873406</td>\n",
       "      <td>-1.634543</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        pca_0     pca_1     pca_2     pca_3     pca_4     pca_5     pca_6  \\\n",
       "0  397.223524  9.202526 -2.189962  4.549270 -2.860389 -0.661128 -1.127714   \n",
       "1 -413.796002 -2.642708 -1.816578  3.667889 -3.706980 -2.615337  2.154200   \n",
       "2 -186.792513 -4.251938 -4.995192  4.231895  2.960767  1.232992 -1.997857   \n",
       "3  609.182722 -3.988165  0.875283 -6.216485  2.647138 -0.395348  2.577097   \n",
       "4  542.184498 -3.108270  1.562811 -5.742595 -0.700203 -0.212724  2.938653   \n",
       "\n",
       "      pca_7     pca_8     pca_9    ...       pca_20    pca_21    pca_22  \\\n",
       "0 -1.576609  2.435424 -0.214111    ...     0.725411 -1.880986 -1.253019   \n",
       "1  0.870472 -1.079709 -1.906726    ...    -1.719804  1.113808 -1.419744   \n",
       "2 -2.006408 -1.497303  1.266953    ...     1.144931  0.094340 -0.533998   \n",
       "3 -1.594666  1.456206 -1.572396    ...     2.252659 -1.107131 -1.518347   \n",
       "4  2.474078  4.090147 -0.824463    ...    -1.404799  1.965380 -1.486253   \n",
       "\n",
       "     pca_23    pca_24    pca_25    pca_26    pca_27    pca_28    pca_29  \n",
       "0  2.886256 -0.980574  2.297412  1.228414 -0.378631 -0.605802  0.823404  \n",
       "1  0.418493  0.472745 -1.704450  1.735314  0.174928 -0.530689  0.675752  \n",
       "2 -0.873726 -1.637557  0.221892 -0.282241  0.688962  1.135661  1.948798  \n",
       "3 -1.274131  0.044414  0.670109  0.130090  2.876533 -0.455379 -1.370996  \n",
       "4 -1.266973 -2.139169 -0.847958 -0.288191  1.387620 -0.873406 -1.634543  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 30\n",
    "pca = PCA(n_components=n, random_state=1)\n",
    "pca.fit(X_train_onehot)\n",
    "tr = pca.transform(X_train_onehot)\n",
    "tr = pd.DataFrame(tr, columns=list(map(lambda i: f'pca_{i}', range(n))))\n",
    "tr.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Одна компонента объясняет 99% дисперсии - очень странный результат."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0.995802922398\n"
     ]
    }
   ],
   "source": [
    "s = 0\n",
    "for i, e in enumerate(sorted(pca.explained_variance_ratio_, key=lambda x: -x)):\n",
    "    s += e\n",
    "    if s >= 0.9:\n",
    "        print(i + 1)\n",
    "        break\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(LogisticRegression(C=0.055, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "           penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
       "           verbose=0, warm_start=False), -0.22288462741954426)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'C': [0.01, 0.04,0.045, 0.05,0.055, 0.057, 0.07, 0.09, 0.1, 0.12, 0.2, 0.3, 0.33, 0.5, 1]}\n",
    "clf = LogisticRegression(penalty='l1', random_state=42)\n",
    "optimizer = GridSearchCV(clf, param_grid, scoring='neg_log_loss', cv=5, n_jobs=-1)\n",
    "optimizer.fit(tr, train.label)\n",
    "optimizer.best_estimator_, optimizer.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# После нескольких запусков PCA с различными n_components, было выбрано значение 30\n",
    "# pca(10), C=0.1:  -0.22436733959923694\n",
    "# pca(40), C=0.05: -0.22347890884850466\n",
    "# pca(30), C=0.05: -0.22277993871800517"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "             max_depth=None, max_features=10, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=8, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, n_estimators=500, n_jobs=-1,\n",
       "             oob_score=False, random_state=42, verbose=0, warm_start=False),\n",
       " -0.22985487329132009)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "    'max_features': [10, 'sqrt', 'log2']\n",
    "}\n",
    "clf = RandomForestClassifier(n_estimators=500, n_jobs=-1, random_state=42)\n",
    "optimizer = GridSearchCV(clf, param_grid, scoring='neg_log_loss', cv=5)\n",
    "optimizer.fit(tr, train.label)\n",
    "optimizer.best_estimator_, optimizer.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что блендинг на преобразованных данных оказался хуже, чем предыдущий."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha: 0.1, score: -0.22279529010960158\n",
      "alpha: 0.2, score: -0.22263431955972193\n",
      "alpha: 0.30000000000000004, score: -0.22274067935721537\n",
      "alpha: 0.4, score: -0.22307952358295272\n",
      "alpha: 0.5, score: -0.22363349410469527\n",
      "alpha: 0.6000000000000001, score: -0.22439522782036905\n",
      "alpha: 0.7000000000000001, score: -0.22536469329770323\n",
      "alpha: 0.8, score: -0.22654854755415524\n",
      "alpha: 0.9, score: -0.22796087570816023\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZQAAAF0CAYAAAAEgc8iAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x17424b0cb00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clf1 = RandomForestClassifier(n_estimators=20000, min_samples_leaf=10, max_features='sqrt',\n",
    "                              criterion='entropy', random_state=42, n_jobs=-1)\n",
    "clf2 = LogisticRegression(penalty='l1', random_state=42, C=0.1)\n",
    "alphas = list(map(lambda i: i*0.1, range(1, 10)))\n",
    "scores = [0]*len(alphas)\n",
    "for i, alpha in enumerate(alphas):\n",
    "    blending = BlendingClassifier(clf1, clf2, alpha=alpha)\n",
    "    scores[i] = cross_val_score(blending, tr, train.label, cv=5, scoring='neg_log_loss')\n",
    "    print(f'alpha: {alpha}, score: {scores[i].mean()}')\n",
    "plot_params_score(alphas, scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поэтому нужно взять RandomForest на изначальных признаках и LogisticRegression на преобразованных. Однако, `BlendingClassifier` не получится запустить, так как в него не получится просунуть преобразование one hot encoding - придется все делать руками."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf1 = RandomForestClassifier(n_estimators=2000, min_samples_leaf=2, max_features=200,\n",
    "                              criterion='entropy', random_state=42, n_jobs=-1)\n",
    "clf2 = LogisticRegression(penalty='l1', random_state=42, C=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha=0.1, loss=0.22122174744406617\n",
      "alpha=0.2, loss=0.2198384419342377\n",
      "alpha=0.30000000000000004, loss=0.218693058784504\n",
      "alpha=0.4, loss=0.2177634670632198\n",
      "alpha=0.5, loss=0.21703738042267884\n",
      "alpha=0.6000000000000001, loss=0.2165096871230403\n",
      "alpha=0.7000000000000001, loss=0.21618171763144206\n",
      "alpha=0.8, loss=0.2160621610721626\n",
      "alpha=0.9, loss=0.2161710321906233\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAF0CAYAAADSJBVHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x17440518358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "alphas = list(map(lambda i: i*0.1, range(1, 10)))\n",
    "scores = [0]*len(alphas)\n",
    "for i, alpha in enumerate(alphas):\n",
    "    skf = StratifiedKFold(n_splits=5, random_state=42)\n",
    "    losses = []\n",
    "    for train_index, test_index in skf.split(X_train_imp, train.label):\n",
    "        clf1.fit(X_train_imp.iloc[train_index], train.label[train_index])\n",
    "        pred1 = clf1.predict_proba(X_train_imp.iloc[test_index])\n",
    "        clf2.fit(tr.iloc[train_index], train.label[train_index])\n",
    "        pred2 = clf2.predict_proba(tr.iloc[test_index])\n",
    "        pred = pred1*alpha + pred2*(1 - alpha)\n",
    "        losses.append(log_loss(train.label[test_index], pred))\n",
    "    print(f'alpha={alpha}, loss={np.mean(losses)}')\n",
    "    scores[i] = losses\n",
    "plot_params_score(alphas, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha=0.75, loss=0.21609498533213375\n",
      "alpha=0.78, loss=0.2160686627857591\n",
      "alpha=0.8, loss=0.2160621610721626\n",
      "alpha=0.82, loss=0.2160647274736359\n",
      "alpha=0.85, loss=0.21608610358087693\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEWCAYAAABMoxE0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x17424af0cc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "alphas = [0.75, 0.78, 0.8, 0.82, 0.85]\n",
    "scores = [0]*len(alphas)\n",
    "for i, alpha in enumerate(alphas):\n",
    "    skf = StratifiedKFold(n_splits=5, random_state=42)\n",
    "    losses = []\n",
    "    for train_index, test_index in skf.split(X_train_imp, train.label):\n",
    "        clf1.fit(X_train_imp.iloc[train_index], train.label[train_index])\n",
    "        pred1 = clf1.predict_proba(X_train_imp.iloc[test_index])\n",
    "        clf2.fit(tr.iloc[train_index], train.label[train_index])\n",
    "        pred2 = clf2.predict_proba(tr.iloc[test_index])\n",
    "        pred = pred1*alpha + pred2*(1 - alpha)\n",
    "        losses.append(log_loss(train.label[test_index], pred))\n",
    "    print(f'alpha={alpha}, loss={np.mean(losses)}')\n",
    "    scores[i] = losses\n",
    "plot_params_score(alphas, scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что оценка получилась лучше, чем при блендинге с логистической регрессией, обученной на числовых и булевых признаках, однако, Public Score оказался хуже."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.05, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf1 = RandomForestClassifier(n_estimators=50000, min_samples_leaf=3, max_features=300,\n",
    "                              criterion='entropy', random_state=42, n_jobs=-1)\n",
    "clf2 = LogisticRegression(penalty='l1', random_state=42, C=0.05)\n",
    "clf1.fit(X_train_imp, train.label)\n",
    "clf2.fit(tr, train.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tr_test = pca.transform(X_test_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alpha = 0.8\n",
    "pred1 = clf1.predict_proba(X_test_imp)\n",
    "pred2 = clf2.predict_proba(tr_test)\n",
    "pred = pred1*alpha + pred2*(1 - alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_test = pd.DataFrame()\n",
    "Y_test['Id'] = np.arange(X_test_imp.shape[0])\n",
    "Y_test['Prediction'] = pred[:, 1]\n",
    "\n",
    "Y_test.to_csv('res1.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В итоге с помощью такого блендинга с `alpha=0.8` удалось добиться\n",
    "\n",
    "`Public Score: 0.23048`,\n",
    "\n",
    "`Private Score: 0.21220`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
