{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если нужно запустить ноутбук, то можно раскомментировать закомментированные строчки, чтобы получить файлы `*.compacted.csv`, которые будут нужны для обучения, а можно (и нужно, так как закомментированный код работает очень долго) скачать их по [ссылке](https://yadi.sk/d/qiGx18123TjDF6)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для событий была предпринята попытка посчитать их количество для каждой команды для каждого `mid`. Так как это считается довольно медленно, это было посчитано один раз и сохранено в `actions.compacted.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "events = pd.read_csv('events.csv')\n",
    "def count_events(event_type, from_team):\n",
    "    def get_series(mid):\n",
    "        return len(events[(events.mid == mid) & (events.event_type == event_type) & (events.from_team == from_team)])\n",
    "    \n",
    "    return get_series\n",
    "\n",
    "actions = ['taken_aegis', 'stolen_aegis', 'enemy_barracks_destroyed', 'first_blood',\n",
    "           'killed_roshan', 'self_tower_destroyed', 'enemy_tower_destroyed']\n",
    "teams = ['radiant', 'dire']\n",
    "# df = pd.DataFrame(data={'mid': list(range(49948))})\n",
    "# for i, action in enumerate(actions):\n",
    "#     for team in teams:\n",
    "#         print(f'{team}_{action}')\n",
    "#         df[f'{team}_{action}'] = df['mid'].map(count_events(i+4, team))\n",
    "#     df.to_csv('actions.compacted.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также для некоторых событий была предпринята попытка посчитать время до первого такого события для команды и добавить в признаки разность времени для `radiant` и `dire`. Например, были добавлены признаки `time_to_first_tower_diff` и `time_to_first_blood_diff`. Однако, эти признаки не улучшили модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_time_diff(event_type):\n",
    "    def f(mid):\n",
    "        table = e[(e.mid == mid) & (e.event_type == event_type)]\n",
    "        radiant_time = table[table.from_team == 'radiant']['time']\n",
    "        dire_time = table[table.from_team == 'dire']['time']\n",
    "        radiant_time = 0 if len(radiant_time) == 0 else radiant_time.iloc[0]\n",
    "        dire_time = 0 if len(dire_time) == 0 else dire_time.iloc[0]\n",
    "        \n",
    "        return radiant_time - dire_time\n",
    "    return f\n",
    "\n",
    "# train['time_to_first_tower_diff'] = train['mid'].map(get_time_diff(6))\n",
    "# train['time_to_first_blood_diff'] = train['mid'].map(get_time_diff(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также было посчитано количество каждого из предметов для команд. Эти вычисления тоже заняли продолжительное время, поэтому результат был сохранен в `items.compacted.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "items = pd.read_csv('items.csv')\n",
    "def get_item(mid, item, radiant):\n",
    "    lower = 0 if radiant else 5\n",
    "    upper = 4 if radiant else 9\n",
    "    return items[(items.mid == mid) & (items.player >= lower) & (items.player <= upper)][f'item_{item}'].sum()\n",
    "\n",
    "# df = pd.DataFrame(data={'mid': list(range(49948))})\n",
    "# for i in range(0, 121):\n",
    "#     print(f'item={i}')\n",
    "#     df[f'item_{i}_radiant'] = df['mid'].map(lambda mid: get_item(mid, i, True))\n",
    "#     df[f'item_{i}_dire'] = df['mid'].map(lambda mid: get_item(mid, i, False))\n",
    "#     df.to_csv(f'items.compacted.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Для того, чтобы отобрать полезные для предсказания предметы, по всем предметам были построены графики зависимости `radiant_won` от разности между количеством определенного предмета у команд. В дальнейшем это не пригодилось, потому что результат логистической регрессии оказался лучше при обучении на разности для всех 120 предметов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hist_by_radiant_win(df, field, bins=50):\n",
    "    groups = df.groupby('radiant_won')[field]\n",
    "    fig, ax = plt.subplots()\n",
    "    for k, v in reversed(list(groups)):\n",
    "        v.hist(label=str(k), alpha=.75, ax=ax, bins=bins)\n",
    "\n",
    "    ax.legend(title='radiant_won')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('items.compacted.csv')\n",
    "def calculate_diff_item(item):\n",
    "    def get_value(mid):\n",
    "        row = df[df.mid == mid]\n",
    "        val = row[f'item_{item}_radiant'] - row[f'item_{item}_dire']\n",
    "        if mid % 10000 == 0:\n",
    "            print(mid)\n",
    "        return val.iloc[0]\n",
    "    return get_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "useful_items = [15, 19, 24, 26, 27, 28, 32,\n",
    "                33, 43, 45, 53, 56, 66, 98, 112]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Для таблиц `gold`, `lh`, `xp` были сагрегированы данные по командам. Было посчитано суммарное значение для команды за 5 и 10 минут, а также суммарное значение для 4 наиболее сильных игроков в команде. Результирующие таблицы были также сохранены в `gold.compacted.csv`, `lh.compacted.csv`, `xp.compacted.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compact(name):\n",
    "    table = pd.read_csv(f'{name}.csv')\n",
    "    \n",
    "    radiant = [f'player_{i}' for i in range(5)]\n",
    "    dire = [f'player_{i}' for i in range(5, 10)]\n",
    "    \n",
    "    table[f'{name}_radiant'] = table[radiant].sum(axis=1)\n",
    "    table[f'{name}_dire'] = table[dire].sum(axis=1)\n",
    "    \n",
    "    table[f'{name}_radiant_5min'] = table[f'{name}_radiant'].shift(5)\n",
    "    table[f'{name}_dire_5min'] = table[f'{name}_dire'].shift(5)\n",
    "    \n",
    "    table[f'{name}_radiant_4'] = table[radiant].sum(axis=1) - table[radiant].min(axis=1) + 1\n",
    "    table[f'{name}_dire_4'] = table[dire].sum(axis=1) - table[dire].min(axis=1) + 1\n",
    "    \n",
    "    table = table[table.times == 600].drop(['times'] + radiant + dire, axis=1)\n",
    "    \n",
    "    table.to_csv(f'{name}.compacted.csv', index=False)\n",
    "    return table\n",
    "\n",
    "# compact('gold')\n",
    "# compact('lh')\n",
    "# compact('xp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Далее создается мешок слов по героям. Для каждого `mid` для каждого героя ставится 1, если герой был в игре и играл за `radiant`, -1, если герой был и играл за `dire` и 0, если героя не было в игре. Результат сохраняется в `heroes.compacted.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_heroes():\n",
    "    N = 110\n",
    "    heroes = np.zeros((data.shape[0], N))\n",
    "\n",
    "    for i, match_id in enumerate(data.index):\n",
    "        for p in range(5):\n",
    "            heroes[i, data.ix[match_id, f'player_{p}']-1] = 1\n",
    "        for p in range(5, 10):\n",
    "            heroes[i, data.ix[match_id, f'player_{p}']-1] = -1\n",
    "\n",
    "    return heroes\n",
    "\n",
    "# heroes = pd.DataFrame({'mid': list(range(49948))})\n",
    "# heroes = heroes.join(pd.DataFrame(get_heroes(), columns=[f'hero_{i}' for i in range(110)]))\n",
    "# heroes.to_csv('heroes.compacted.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При генерировании признаков было написано два метода: `enrich` и `enrich_diff`. В `enrich` отдельно записывались признаки для `radiant` и `dire`. В `enrich_diff` для всех таких признаков взята разница `feature_radiant` - `feature_dire`. Модель, создаваемая в `enrich_diff` оказалась лучше, поэтому в дальнейшем используется она."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "events = pd.read_csv('actions.compacted.csv')\n",
    "items = pd.read_csv('items.compacted.csv')\n",
    "gold = pd.read_csv('gold.compacted.csv')\n",
    "lh = pd.read_csv('lh.compacted.csv')\n",
    "xp = pd.read_csv('xp.compacted.csv')\n",
    "\n",
    "useful_events = ['first_blood', 'killed_roshan', 'enemy_barracks_destroyed', 'self_tower_destroyed', 'enemy_tower_destroyed']\n",
    "\n",
    "def enrich(data):\n",
    "    data = data.merge(events[['mid'] +\n",
    "                             [f'radiant_{event}' for event in useful_events] +\n",
    "                             [f'dire_{event}' for event in useful_events]], on='mid', how='left')\n",
    "\n",
    "    data = data.merge(heroes, on='mid', how='left')\n",
    "    \n",
    "    data = data.merge(items[['mid'] +\n",
    "                            [f'item_{x}_radiant' for x in range(121)] +\n",
    "                            [f'item_{x}_dire' for x in range(121)]], on='mid', how='left')\n",
    "\n",
    "    data = data.merge(gold, on='mid', how='left')\n",
    "    data = data.merge(lh, on='mid', how='left')\n",
    "    data = data.merge(xp, on='mid', how='left')\n",
    "    \n",
    "    return data\n",
    "\n",
    "def merge(data, table, name, names):\n",
    "    table[f'{name}_diff'] = table[f'{name}_radiant'] - table[f'{name}_dire']\n",
    "    table[f'{name}_5min_diff'] = table[f'{name}_radiant_5min'] - table[f'{name}_dire_5min']\n",
    "    table[f'{name}_4players_diff'] = table[f'{name}_radiant_4'] - table[f'{name}_dire_4']\n",
    "    table[f'{name}_diff_sqrt'] = (table[f'{name}_radiant'] - table[f'{name}_dire']) / np.sqrt(table[f'{name}_radiant'] + table[f'{name}_dire'])\n",
    "    table[f'{name}_ratio'] = table[f'{name}_radiant'] / table[f'{name}_dire']\n",
    "    return data.merge(table[['mid'] + [f'{name}_{x}' for x in names]], on='mid', how='left')\n",
    "    \n",
    "def enrich_diff(data):\n",
    "    for event in useful_events:\n",
    "        events[f'{event}_diff'] = events[f'radiant_{event}'] - events[f'dire_{event}']\n",
    "        \n",
    "    data = data.merge(events[['mid'] + [f'{event}_diff' for event in useful_events]], on='mid', how='left')\n",
    "    \n",
    "    heroes = pd.read_csv('heroes.compacted.csv')\n",
    "    data = data.merge(heroes, on='mid', how='left')\n",
    "    \n",
    "    for item in range(121):\n",
    "        items[f'item_{item}_diff'] = items[f'item_{item}_radiant'] - items[f'item_{item}_dire']\n",
    "        \n",
    "    data = data.merge(items[['mid'] + [f'item_{item}_diff' for item in range(121)]], on='mid', how='left')\n",
    "    \n",
    "    data = merge(data, gold, 'gold', ['diff', '5min_diff', '4players_diff'])\n",
    "    data = merge(data, lh, 'lh', ['diff', 'diff_sqrt'])\n",
    "    data = merge(data, xp, 'xp', ['diff', 'diff_sqrt'])\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При обучении сначала использовался случайный лес, однако, логистическая регрессия показала себя значительно лучше, поэтому в дальнейшем используется она. Для масштабированя признаков было опробовано не масштабировать признаки вообще, использовать `StandardScaler` или использовать `RobustScaler`. `StandardScaler` показал наилучший результат. При обучении линейной регрессии были испробованы регуляризация L1 и L2, L1 показала лучший результат. Также для подбора параметра регуляризации `C` был использован `GridSearchCV`, с помощью которого был найден оптимальный параметр `C=0.548`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_result(clf, scale=False):\n",
    "    X = train.drop('radiant_won', axis=1).drop('mid', axis=1)\n",
    "    y = train['radiant_won']\n",
    "    X_test = test.drop('mid', axis=1)\n",
    "    if scale:\n",
    "        scaler = StandardScaler()\n",
    "        X[:] = scaler.fit_transform(X)\n",
    "        X_test[:] = scaler.transform(X_test)\n",
    "    clf.fit(X, y)\n",
    "    pred = clf.predict_proba(X_test)[:,1:]\n",
    "    pred_data = pd.read_csv('test.csv')\n",
    "    pred_data['radiant_won'] = pred\n",
    "    pred_data.to_csv('res.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = enrich_diff(pd.read_csv('train.csv'))\n",
    "test = enrich_diff(pd.read_csv('test.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = train.drop('radiant_won', axis=1).drop('mid', axis=1)\n",
    "y = train['radiant_won']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X[:] = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 3 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:   15.9s\n",
      "[Parallel(n_jobs=-1)]: Done  22 out of  30 | elapsed:   49.6s remaining:   18.0s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:  1.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(LogisticRegression(C=0.0548, class_weight=None, dual=False,\n",
       "           fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "           multi_class='ovr', n_jobs=1, penalty='l1', random_state=42,\n",
       "           solver='liblinear', tol=0.0001, verbose=0, warm_start=False),\n",
       " 0.7676739313139288)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'C': [0.54, 0.0548, 0.55]}\n",
    "optimizer = GridSearchCV(LogisticRegression(penalty='l1', random_state=42),\n",
    "                         param_grid, scoring='roc_auc', cv=10, verbose=5, n_jobs=-1)\n",
    "optimizer.fit(X, y)\n",
    "optimizer.best_estimator_, optimizer.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_result(LogisticRegression(random_state=42, C=0.0548, penalty='l1'), scale=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Была также предпринята попытка добавить в признаки пары героев (предполагалось, что некоторые герои хорошо играют в паре), для этого посчитаны винрейты для пар героев. Однако, эти признаки не сказались положительно на качестве и в финальной модели не присутствовали."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "heroes = pd.read_csv('heroes.compacted.csv')\n",
    "cols = []\n",
    "for i in range(110):\n",
    "    for j in range(i + 1, 110):\n",
    "        col = f'heroes_{i}_{j}'\n",
    "        cols.append(col)\n",
    "        heroes[col] = heroes[f'hero_{i}'] + heroes[f'hero_{j}']\n",
    "\n",
    "train = train.merge(heroes[['mid'] + cols], on='mid', how='left')\n",
    "\n",
    "win_rates = {}\n",
    "for i in range(110):\n",
    "    for j in range(i+1, 110):\n",
    "        col = f'heroes_{i}_{j}'\n",
    "        plays_count = len(train[(train[col] == -2) | (train[col] == 2)])\n",
    "        win_rates[col] = 0 if plays_count == 0 else (\n",
    "            len(train[(train[col] == -2) & (train['radiant_won'] == 0)]) +\n",
    "            len(train[(train[col] == 2) & (train['radiant_won'] == 1)])\n",
    "        ) / plays_count, plays_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "heroes_7_16 0.34806629834254144 181\n",
      "heroes_19_64 0.6583850931677019 161\n",
      "heroes_23_58 0.345 200\n",
      "heroes_28_49 0.654054054054054 185\n",
      "heroes_28_67 0.6511627906976745 172\n",
      "heroes_28_88 0.6545454545454545 220\n",
      "heroes_28_108 0.7401960784313726 204\n",
      "heroes_31_49 0.6538461538461539 234\n",
      "heroes_38_67 0.6547619047619048 168\n",
      "heroes_39_88 0.6772727272727272 220\n",
      "heroes_49_68 0.6625 160\n",
      "heroes_56_64 0.6619047619047619 210\n",
      "heroes_58_80 0.34415584415584416 154\n",
      "heroes_64_66 0.6653386454183267 251\n",
      "heroes_64_67 0.680365296803653 219\n",
      "heroes_64_70 0.6591928251121076 223\n",
      "heroes_64_93 0.651685393258427 267\n",
      "heroes_89_93 0.6566265060240963 166\n",
      "heroes_93_108 0.6612377850162866 307\n"
     ]
    }
   ],
   "source": [
    "interesting_pairs = []\n",
    "for k,(v,n) in win_rates.items():\n",
    "    if (v < 0.35 and v != 0 or v > 0.65) and n > 150:\n",
    "        print(k,v,n)\n",
    "        interesting_pairs.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = enrich_diff(pd.read_csv('train.csv'))\n",
    "train = train.merge(heroes[['mid'] + interesting_pairs], on='mid', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize(pair_value):\n",
    "    if pair_value == 1 or -1:\n",
    "        return 0\n",
    "    \n",
    "    if pair_value == 2:\n",
    "        return 1\n",
    "    \n",
    "    if pair_value == -2:\n",
    "        return -1\n",
    "    \n",
    "for e in interesting_pairs:\n",
    "    train[e] = train[e].map(normalize)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
